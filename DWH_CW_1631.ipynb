{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ad642bf-61d8-49e6-a6e7-8c6279278f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce431b51-b960-4c86-b907-56154563cc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database already exists locally.\n",
      "Connected to the Northwind database.\n",
      "Tables in the database:\n",
      "                    name\n",
      "0             Categories\n",
      "1        sqlite_sequence\n",
      "2   CustomerCustomerDemo\n",
      "3   CustomerDemographics\n",
      "4              Customers\n",
      "5              Employees\n",
      "6    EmployeeTerritories\n",
      "7          Order Details\n",
      "8                 Orders\n",
      "9               Products\n",
      "10               Regions\n",
      "11              Shippers\n",
      "12             Suppliers\n",
      "13           Territories\n"
     ]
    }
   ],
   "source": [
    "# Define the file path and URL\n",
    "db_filename = \"northwind.sqlite\"\n",
    "db_path = f\"./db/{db_filename}\"\n",
    "db_url = \"https://raw.githubusercontent.com/jpwhite3/northwind-SQLite3/main/dist/northwind.db\"\n",
    "\n",
    "# Step 1: Download the database if it doesn't exist\n",
    "if not os.path.exists(db_path):\n",
    "    print(\"Downloading Northwind database...\")\n",
    "    urllib.request.urlretrieve(db_url, db_path)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"Database already exists locally.\")\n",
    "\n",
    "# Step 2: Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "print(\"Connected to the Northwind database.\")\n",
    "\n",
    "# Step 3: (Optional) List available tables\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(\"Tables in the database:\")\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22d1b80e-7a89-44af-b086-93b43516febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Step 2: Load Required Tables\n",
    "# -------------------------------\n",
    "customers_df = pd.read_sql(\"SELECT * FROM Customers\", conn)\n",
    "orders_df = pd.read_sql(\"SELECT * FROM Orders\", conn)\n",
    "order_details_df = pd.read_sql(\"SELECT * FROM 'Order Details'\", conn)\n",
    "products_df = pd.read_sql(\"SELECT * FROM Products\", conn)\n",
    "categories_df = pd.read_sql(\"SELECT * FROM Categories\", conn)\n",
    "suppliers_df = pd.read_sql(\"SELECT * FROM Suppliers\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51f65660-56f6-434b-83b7-5a4a46dfb643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- customers_df ---\n",
      "Null values before filling:\n",
      "Address        2\n",
      "City           2\n",
      "Region         2\n",
      "PostalCode     3\n",
      "Country        2\n",
      "Phone          2\n",
      "Fax           24\n",
      "dtype: int64\n",
      "No duplicate rows found.\n",
      "customers_df: nulls filled and duplicates handled.\n",
      "\n",
      "--- orders_df ---\n",
      "Null values before filling:\n",
      "ShippedDate        21\n",
      "ShipPostalCode    172\n",
      "dtype: int64\n",
      "No duplicate rows found.\n",
      "orders_df: nulls filled and duplicates handled.\n",
      "\n",
      "--- order_details_df ---\n",
      "Null values before filling:\n",
      "Series([], dtype: int64)\n",
      "No duplicate rows found.\n",
      "order_details_df: nulls filled and duplicates handled.\n",
      "\n",
      "--- products_df ---\n",
      "Null values before filling:\n",
      "Series([], dtype: int64)\n",
      "No duplicate rows found.\n",
      "products_df: nulls filled and duplicates handled.\n",
      "\n",
      "--- categories_df ---\n",
      "Null values before filling:\n",
      "Series([], dtype: int64)\n",
      "No duplicate rows found.\n",
      "categories_df: nulls filled and duplicates handled.\n",
      "\n",
      "--- suppliers_df ---\n",
      "Null values before filling:\n",
      "Region       1\n",
      "Fax         16\n",
      "HomePage    24\n",
      "dtype: int64\n",
      "No duplicate rows found.\n",
      "suppliers_df: nulls filled and duplicates handled.\n"
     ]
    }
   ],
   "source": [
    "# Define the list of DataFrame names to process\n",
    "dataframes = ['customers_df', 'orders_df', 'order_details_df', 'products_df', 'categories_df', 'suppliers_df']\n",
    "\n",
    "# Placeholder for missing values\n",
    "placeholder = 'Unknown'\n",
    "\n",
    "# Process each DataFrame\n",
    "for df_name in dataframes:\n",
    "    df = globals()[df_name]\n",
    "\n",
    "    # Check and print null value counts\n",
    "    nulls = df.isna().sum()\n",
    "    print(f\"\\n--- {df_name} ---\")\n",
    "    print(\"Null values before filling:\")\n",
    "    print(nulls[nulls > 0])\n",
    "\n",
    "    # Fill NaN values with placeholder\n",
    "    df = df.fillna(placeholder)\n",
    "\n",
    "    # Check for duplicates\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"{duplicate_count} duplicate rows found in {df_name}. Removing them.\")\n",
    "        df = df.drop_duplicates()\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")\n",
    "\n",
    "    # Save back to the global variable\n",
    "    globals()[df_name] = df\n",
    "\n",
    "    # Confirm\n",
    "    print(f\"{df_name}: nulls filled and duplicates handled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efbb96c2-4e1e-42ee-94b1-5bc93a165e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact Table:\n",
      "   OrderID CustomerID  ProductID  OrderDate  Quantity  UnitPrice  Discount  \\\n",
      "0    10248      VINET         11 2016-07-04        12       14.0       0.0   \n",
      "1    10248      VINET         42 2016-07-04        10        9.8       0.0   \n",
      "2    10248      VINET         72 2016-07-04         5       34.8       0.0   \n",
      "3    10249      TOMSP         14 2016-07-05         9       18.6       0.0   \n",
      "4    10249      TOMSP         51 2016-07-05        40       42.4       0.0   \n",
      "\n",
      "   RevenueUSD  \n",
      "0       168.0  \n",
      "1        98.0  \n",
      "2       174.0  \n",
      "3       167.4  \n",
      "4      1696.0  \n",
      "\n",
      "dim_customer:\n",
      "  CustomerID                         CompanyName         ContactName  \\\n",
      "0      ALFKI                 Alfreds Futterkiste        Maria Anders   \n",
      "1      ANATR  Ana Trujillo Emparedados y helados        Ana Trujillo   \n",
      "2      ANTON             Antonio Moreno Taquería      Antonio Moreno   \n",
      "3      AROUT                     Around the Horn        Thomas Hardy   \n",
      "4      BERGS                  Berglunds snabbköp  Christina Berglund   \n",
      "\n",
      "          City  Country  \n",
      "0       Berlin  Germany  \n",
      "1  México D.F.   Mexico  \n",
      "2  México D.F.   Mexico  \n",
      "3       London       UK  \n",
      "4        Luleå   Sweden  \n",
      "\n",
      "dim_product:\n",
      "   ProductID                   ProductName CategoryName  \\\n",
      "0          1                          Chai    Beverages   \n",
      "1          2                         Chang    Beverages   \n",
      "2          3                 Aniseed Syrup   Condiments   \n",
      "3          4  Chef Anton's Cajun Seasoning   Condiments   \n",
      "4          5        Chef Anton's Gumbo Mix   Condiments   \n",
      "\n",
      "                 SupplierName SupplierCountry  \n",
      "0              Exotic Liquids              UK  \n",
      "1              Exotic Liquids              UK  \n",
      "2              Exotic Liquids              UK  \n",
      "3  New Orleans Cajun Delights             USA  \n",
      "4  New Orleans Cajun Delights             USA  \n",
      "\n",
      "dim_date:\n",
      "   OrderID  OrderDate  Year  Month  Day\n",
      "0    10248 2016-07-04  2016      7    4\n",
      "1    10249 2016-07-05  2016      7    5\n",
      "2    10250 2016-07-08  2016      7    8\n",
      "3    10251 2016-07-08  2016      7    8\n",
      "4    10252 2016-07-09  2016      7    9\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Step 3: Build Dimension Tables\n",
    "# -------------------------------\n",
    "\n",
    "# dim_customer\n",
    "dim_customer = customers_df[[\n",
    "    'CustomerID', 'CompanyName', 'ContactName', 'City', 'Country'\n",
    "]].copy()\n",
    "\n",
    "# dim_product (merge categories and suppliers)\n",
    "dim_product = products_df.merge(categories_df, on='CategoryID', how='left') \\\n",
    "                         .merge(suppliers_df, on='SupplierID', how='left')\n",
    "\n",
    "dim_product = dim_product[[\n",
    "    'ProductID', 'ProductName', 'CategoryName', 'CompanyName', 'Country'\n",
    "]].rename(columns={\n",
    "    'CompanyName': 'SupplierName',\n",
    "    'Country': 'SupplierCountry'\n",
    "})\n",
    "\n",
    "# dim_date\n",
    "orders_df['OrderDate'] = pd.to_datetime(orders_df['OrderDate'], format='mixed')\n",
    "dim_date = orders_df[['OrderID', 'OrderDate']].copy()\n",
    "dim_date['Year'] = dim_date['OrderDate'].dt.year\n",
    "dim_date['Month'] = dim_date['OrderDate'].dt.month\n",
    "dim_date['Day'] = dim_date['OrderDate'].dt.day\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Build Fact Table\n",
    "# -------------------------------\n",
    "\n",
    "fact_sales = order_details_df.merge(\n",
    "    orders_df[['OrderID', 'CustomerID', 'OrderDate']], \n",
    "    on='OrderID', how='left'\n",
    ").merge(\n",
    "    products_df[['ProductID', 'ProductName']], \n",
    "    on='ProductID', how='left'\n",
    ")\n",
    "\n",
    "fact_sales['OrderDate'] = pd.to_datetime(fact_sales['OrderDate'])\n",
    "fact_sales['RevenueUSD'] = fact_sales['UnitPrice'] * fact_sales['Quantity']\n",
    "\n",
    "fact_sales = fact_sales[[\n",
    "    'OrderID', 'CustomerID', 'ProductID', 'OrderDate', \n",
    "    'Quantity', 'UnitPrice', 'Discount', 'RevenueUSD'\n",
    "]]\n",
    "\n",
    "# -------------------------------\n",
    "# Done: Preview Outputs\n",
    "# -------------------------------\n",
    "print(\"Fact Table:\")\n",
    "print(fact_sales.head())\n",
    "\n",
    "print(\"\\ndim_customer:\")\n",
    "print(dim_customer.head())\n",
    "\n",
    "print(\"\\ndim_product:\")\n",
    "print(dim_product.head())\n",
    "\n",
    "print(\"\\ndim_date:\")\n",
    "print(dim_date.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2d3a922-41c6-4c4e-a446-b9e152cba921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID                         CompanyName         ContactName  \\\n",
      "0      ALFKI                 Alfreds Futterkiste        Maria Anders   \n",
      "1      ANATR  Ana Trujillo Emparedados y helados        Ana Trujillo   \n",
      "2      ANTON             Antonio Moreno Taquería      Antonio Moreno   \n",
      "3      AROUT                     Around the Horn        Thomas Hardy   \n",
      "4      BERGS                  Berglunds snabbköp  Christina Berglund   \n",
      "\n",
      "          City  Country            Region  Latitude  Longitude  CityPopulation  \n",
      "0       Berlin  Germany            Berlin   52.5200    13.4050       4890363.0  \n",
      "1  México D.F.   Mexico  Ciudad de México   19.4333   -99.1333      21804000.0  \n",
      "2  México D.F.   Mexico  Ciudad de México   19.4333   -99.1333      21804000.0  \n",
      "3       London       UK   London, City of   51.5072    -0.1275      11262000.0  \n",
      "4        Luleå   Sweden        Norrbotten   65.5844    22.1539         49123.0  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Step 1: Load the world cities CSV\n",
    "# -------------------------------\n",
    "cities_path = \"worldcities.csv\"  # Replace with your actual path if needed\n",
    "world_cities = pd.read_csv(cities_path)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Prepare dim_customer and world_cities for join\n",
    "# -------------------------------\n",
    "# Create lowercase versions of city and country names for matching\n",
    "dim_customer['City_lower'] = dim_customer['City'].str.lower()\n",
    "dim_customer['Country_lower'] = dim_customer['Country'].str.lower()\n",
    "world_cities['city_lower'] = world_cities['city'].str.lower()\n",
    "world_cities['country_lower'] = world_cities['country'].str.lower()\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Define custom fixes for unmatched names\n",
    "# -------------------------------\n",
    "city_fix = {\n",
    "    \"bruxelles\": \"brussels\",\n",
    "    \"sao paulo\": \"são paulo\",\n",
    "    \"tsawassen\": \"vancouver\",\n",
    "    \"kobenhavn\": \"copenhagen\",\n",
    "    \"århus\": \"aarhus\",\n",
    "    \"cunewalde\": \"dresden\",\n",
    "    \"frankfurt a.m.\": \"frankfurt\",\n",
    "    \"köln\": \"cologne\",\n",
    "    \"münchen\": \"munich\",\n",
    "    \"torino\": \"turin\",\n",
    "    \"méxico d.f.\": \"mexico city\",\n",
    "    \"stavern\": \"oslo\",\n",
    "    \"warszawa\": \"warsaw\",\n",
    "    \"lisboa\": \"lisbon\",\n",
    "    \"bräcke\": \"östersund\",\n",
    "    \"genève\": \"geneva\",\n",
    "    \"cowes\": \"southampton\",\n",
    "    \"albuquerque\": \"albuquerque\",\n",
    "    \"anchorage\": \"anchorage\"\n",
    "}\n",
    "\n",
    "country_fix = {\n",
    "    \"uk\": \"united kingdom\",\n",
    "    \"usa\": \"united states\"\n",
    "}\n",
    "\n",
    "# Apply fixes to standardized city and country columns\n",
    "dim_customer['City_lower'] = dim_customer['City_lower'].replace(city_fix)\n",
    "dim_customer['Country_lower'] = dim_customer['Country_lower'].replace(country_fix)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Join dim_customer with world_cities\n",
    "# -------------------------------\n",
    "enriched_customer = dim_customer.merge(\n",
    "    world_cities,\n",
    "    left_on=['City_lower', 'Country_lower'],\n",
    "    right_on=['city_lower', 'country_lower'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Finalize the enriched dim_customer\n",
    "# -------------------------------\n",
    "enriched_customer = enriched_customer[[\n",
    "    'CustomerID', 'CompanyName', 'ContactName', 'City', 'Country',\n",
    "    'admin_name', 'lat', 'lng', 'population'\n",
    "]].rename(columns={\n",
    "    'admin_name': 'Region',\n",
    "    'lat': 'Latitude',\n",
    "    'lng': 'Longitude',\n",
    "    'population': 'CityPopulation'\n",
    "})\n",
    "\n",
    "# -------------------------------\n",
    "# Preview\n",
    "# -------------------------------\n",
    "print(enriched_customer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b05b564d-6e56-4727-ad94-c83ff22e35e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current USD to UZS rate: 12947.07\n",
      "   OrderID  RevenueUSD    RevenueUZS\n",
      "0    10248       168.0  2.175108e+06\n",
      "1    10248        98.0  1.268813e+06\n",
      "2    10248       174.0  2.252790e+06\n",
      "3    10249       167.4  2.167340e+06\n",
      "4    10249      1696.0  2.195823e+07\n"
     ]
    }
   ],
   "source": [
    "# Step 1: CBU API URL for exchange rates (returns JSON)\n",
    "url = \"https://cbu.uz/ru/arkhiv-kursov-valyut/json/\"\n",
    "\n",
    "try:\n",
    "    # Step 2: Request exchange rate data\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Step 3: Extract USD to UZS rate from JSON\n",
    "    usd_to_uzs_rate = next(\n",
    "        (float(item['Rate'].replace(',', '')) for item in data if item['Ccy'] == 'USD'),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if usd_to_uzs_rate:\n",
    "        print(f\"Current USD to UZS rate: {usd_to_uzs_rate}\")\n",
    "\n",
    "        # Step 4: Convert USD revenue to UZS in fact_sales\n",
    "        fact_sales['RevenueUZS'] = fact_sales['RevenueUSD'] * usd_to_uzs_rate\n",
    "\n",
    "    else:\n",
    "        print(\"USD exchange rate not found in response.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error fetching exchange rate from CBU API:\", e)\n",
    "    usd_to_uzs_rate = None\n",
    "\n",
    "# Step 5: Preview\n",
    "print(fact_sales[['OrderID', 'RevenueUSD', 'RevenueUZS']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "604ee76e-019c-4901-b299-cfe732f12286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data warehouse schema stored successfully in SQLite:\n",
      "           name\n",
      "0    fact_sales\n",
      "1   dim_product\n",
      "2      dim_date\n",
      "3  dim_customer\n"
     ]
    }
   ],
   "source": [
    "# Define the DW database file\n",
    "dwh_path = \"northwind_dwh.db\"\n",
    "\n",
    "# Connect to (or create) the DW SQLite database\n",
    "dwh_conn = sqlite3.connect(dwh_path)\n",
    "\n",
    "# Ensure enriched_customer_fixed points to the latest enriched customer dimension\n",
    "enriched_customer_fixed = enriched_customer\n",
    "\n",
    "# Write DataFrames to the database (replace existing if any)\n",
    "fact_sales.to_sql(\"fact_sales\", dwh_conn, if_exists=\"replace\", index=False)\n",
    "dim_product.to_sql(\"dim_product\", dwh_conn, if_exists=\"replace\", index=False)\n",
    "dim_date.to_sql(\"dim_date\", dwh_conn, if_exists=\"replace\", index=False)\n",
    "enriched_customer_fixed.to_sql(\"dim_customer\", dwh_conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Optional: Confirm tables are created\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", dwh_conn)\n",
    "print(\"✅ Data warehouse schema stored successfully in SQLite:\")\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "275003af-b015-4984-9980-61d8492ad4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite DW\n",
    "conn = sqlite3.connect(\"northwind_dwh.db\")\n",
    "\n",
    "# OLAP queries\n",
    "\n",
    "# Connect to the data warehouse SQLite DB\n",
    "dwh_conn = sqlite3.connect(\"northwind_dwh.db\")\n",
    "\n",
    "# Load Roll-Up: Revenue by Year and Country\n",
    "rollup_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT d.Year, c.Country, SUM(f.RevenueUZS) AS TotalRevenueUZS\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_customer c ON f.CustomerID = c.CustomerID\n",
    "    JOIN dim_date d ON f.OrderID = d.OrderID\n",
    "    WHERE d.Year IS NOT NULL\n",
    "    GROUP BY d.Year, c.Country\n",
    "    ORDER BY d.Year, TotalRevenueUZS DESC;\n",
    "\"\"\", conn)\n",
    "\n",
    "# Load Slice & Dice: USA + Beverages\n",
    "slice_dice_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT c.Country, p.CategoryName, d.Year, SUM(f.RevenueUZS) AS Revenue\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_customer c ON f.CustomerID = c.CustomerID\n",
    "    JOIN dim_product p ON f.ProductID = p.ProductID\n",
    "    JOIN dim_date d ON f.OrderID = d.OrderID\n",
    "    WHERE c.Country = 'USA' AND p.CategoryName = 'Beverages'\n",
    "    GROUP BY c.Country, p.CategoryName, d.Year\n",
    "    ORDER BY d.Year;\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "drilldown_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT d.Year, d.Month, c.Country, p.CategoryName, SUM(f.RevenueUZS) AS MonthlyRevenue\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_date d ON f.OrderID = d.OrderID\n",
    "    JOIN dim_customer c ON f.CustomerID = c.CustomerID\n",
    "    JOIN dim_product p ON f.ProductID = p.ProductID\n",
    "    GROUP BY d.Year, d.Month, c.Country, p.CategoryName\n",
    "\"\"\", conn)\n",
    "\n",
    "top_categories_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT p.CategoryName, SUM(f.RevenueUZS) AS TotalRevenue\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_product p ON f.ProductID = p.ProductID\n",
    "    GROUP BY p.CategoryName\n",
    "    ORDER BY TotalRevenue DESC\n",
    "    LIMIT 5;\n",
    "\"\"\", conn)\n",
    "\n",
    "pivot_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT c.Country, p.CategoryName, SUM(f.RevenueUZS) AS Revenue\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_customer c ON f.CustomerID = c.CustomerID\n",
    "    JOIN dim_product p ON f.ProductID = p.ProductID\n",
    "    GROUP BY c.Country, p.CategoryName;\n",
    "\"\"\", conn)\n",
    "\n",
    "segmentation_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        c.CustomerID, c.Country,\n",
    "        SUM(f.RevenueUZS) AS TotalSpend,\n",
    "        CASE \n",
    "            WHEN SUM(f.RevenueUZS) >= 70000000000 THEN 'High'\n",
    "            WHEN SUM(f.RevenueUZS) >= 50000000000 THEN 'Medium'\n",
    "            ELSE 'Low'\n",
    "        END AS SpendTier\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_customer c ON f.CustomerID = c.CustomerID\n",
    "    GROUP BY c.CustomerID, c.Country;\n",
    "\"\"\", conn)\n",
    "\n",
    "map_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        c.City, \n",
    "        c.Country, \n",
    "        c.Latitude, \n",
    "        c.Longitude, \n",
    "        SUM(f.RevenueUZS) AS TotalRevenue\n",
    "    FROM fact_sales f\n",
    "    JOIN dim_customer c ON f.CustomerID = c.CustomerID\n",
    "    WHERE c.Latitude IS NOT NULL AND c.Longitude IS NOT NULL\n",
    "    GROUP BY c.City, c.Country, c.Latitude, c.Longitude\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "# Filters\n",
    "years = pd.read_sql(\"SELECT DISTINCT Year FROM dim_date WHERE Year IS NOT NULL ORDER BY Year\", conn)['Year'].dropna().astype(int).tolist()\n",
    "countries = pd.read_sql(\"SELECT DISTINCT Country FROM dim_customer ORDER BY Country\", conn)['Country'].dropna().tolist()\n",
    "categories = pd.read_sql(\"SELECT DISTINCT CategoryName FROM dim_product ORDER BY CategoryName\", conn)['CategoryName'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "224e1ea7-ffb2-40ac-9335-ccd978ab1249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8051/\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "window.open('http://127.0.0.1:8051/')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dash App\n",
    "app = dash.Dash(__name__)\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Northwind OLAP Dashboard\", style={\n",
    "        'textAlign': 'center', 'fontFamily': 'Segoe UI, sans-serif', 'fontSize': '40px', 'marginBottom': '40px'\n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label(\"Filter by Year (Range):\", style={'fontWeight': 'bold', 'fontFamily': 'Segoe UI, sans-serif'}),\n",
    "        dcc.RangeSlider(\n",
    "            id='year-slider', min=min(years), max=max(years),\n",
    "            marks={year: str(year) for year in years},\n",
    "            value=[min(years), max(years)]\n",
    "        ),\n",
    "        html.Label(\"Select Countries:\", style={'fontWeight': 'bold', 'fontFamily': 'Segoe UI, sans-serif', 'marginTop': '20px'}),\n",
    "        dcc.Dropdown(\n",
    "            id='country-dropdown',\n",
    "            options=[{\"label\": c, \"value\": c} for c in countries],\n",
    "            value=countries,\n",
    "            multi=True\n",
    "        ),\n",
    "        html.Label(\"Select Product Categories:\", style={'fontWeight': 'bold', 'fontFamily': 'Segoe UI, sans-serif', 'marginTop': '20px'}),\n",
    "        dcc.Dropdown(\n",
    "            id='category-dropdown',\n",
    "            options=[{\"label\": cat, \"value\": cat} for cat in categories],\n",
    "            value=categories,\n",
    "            multi=True\n",
    "        )\n",
    "    ], style={'width': '80%', 'margin': 'auto', 'marginBottom': '40px'}),\n",
    "\n",
    "    html.H2(\"Monthly Revenue Over Time\", style={\n",
    "        'fontFamily': 'Segoe UI, sans-serif',\n",
    "        'fontSize': '26px',\n",
    "        'marginTop': '40px'\n",
    "    }),\n",
    "    dcc.Graph(id='monthly-revenue-chart'),\n",
    "    \n",
    "    html.H2(\"Top Product Categories\", style={\n",
    "        'fontFamily': 'Segoe UI, sans-serif',\n",
    "        'fontSize': '26px',\n",
    "        'marginTop': '40px'\n",
    "    }),\n",
    "    dcc.Graph(id='top-categories-chart'),\n",
    "    \n",
    "    html.H2(\"Heatmap: Revenue by Country & Category\", style={\n",
    "        'fontFamily': 'Segoe UI, sans-serif',\n",
    "        'fontSize': '26px',\n",
    "        'marginTop': '40px'\n",
    "    }),    \n",
    "    dcc.Graph(id='pivot-chart', style={'height': '800px'}),\n",
    "    \n",
    "    html.H2(\"Customer Spend Tiers\", style={\n",
    "        'fontFamily': 'Segoe UI, sans-serif',\n",
    "        'fontSize': '26px',\n",
    "        'marginTop': '40px'\n",
    "    }),\n",
    "    dcc.Graph(id='segmentation-chart'),\n",
    "\n",
    "    html.H2(\"Top 5 Countries by Revenue\", style={\n",
    "        'fontFamily': 'Segoe UI, sans-serif',\n",
    "        'fontSize': '26px',\n",
    "        'marginTop': '40px'\n",
    "    }),\n",
    "    dcc.Graph(id='top5-stacked-bar', style={'height': '600px'}),\n",
    "\n",
    "    html.H2(\"Country Revenue Trends Over Time\", style={\n",
    "        'fontFamily': 'Segoe UI, sans-serif', 'fontSize': '26px', 'marginTop': '40px'\n",
    "    }),\n",
    "    dcc.Graph(id='country-line-chart', style={'height': '600px'}),\n",
    "\n",
    "    html.H2(\"Revenue in USA for Beverages by Year\", style={\n",
    "        'fontFamily': 'Segoe UI, sans-serif',\n",
    "        'fontSize': '26px',\n",
    "        'marginTop': '40px'\n",
    "    }),\n",
    "    dcc.Graph(id='slice-dice-chart'),\n",
    "    \n",
    "    html.H2(\"Customer Revenue by City\", style={\n",
    "        'fontFamily': 'Segoe UI, sans-serif',\n",
    "        'fontSize': '26px',\n",
    "        'marginTop': '40px'\n",
    "    }),\n",
    "    dcc.Graph(id='revenue-map', style={'height': '700px'})\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    [\n",
    "        Output('monthly-revenue-chart', 'figure'),\n",
    "        Output('top-categories-chart', 'figure'),\n",
    "        Output('pivot-chart', 'figure'),\n",
    "        Output('segmentation-chart', 'figure'),\n",
    "        Output('top5-stacked-bar', 'figure'),\n",
    "        Output('country-line-chart', 'figure'),\n",
    "        Output('slice-dice-chart', 'figure'),\n",
    "        Output('revenue-map', 'figure')\n",
    "    ],\n",
    "    [\n",
    "        Input('year-slider', 'value'),\n",
    "        Input('country-dropdown', 'value'),\n",
    "        Input('category-dropdown', 'value')\n",
    "    ]\n",
    ")\n",
    "def update_charts(year_range, selected_countries, selected_categories):\n",
    "    y1, y2 = year_range\n",
    "    drill = drilldown_df.query(\"Country in @selected_countries and CategoryName in @selected_categories and @y1 <= Year <= @y2\")\n",
    "    monthly = drill.groupby(['Year', 'Month'])['MonthlyRevenue'].sum().reset_index()\n",
    "    top = top_categories_df.query(\"CategoryName in @selected_categories\")\n",
    "    pivot = pivot_df.query(\"Country in @selected_countries and CategoryName in @selected_categories\")\n",
    "    seg = segmentation_df.query(\"Country in @selected_countries\")\n",
    "\n",
    "    rollup_filtered = rollup_df.query(\"@y1 <= Year <= @y2 and Country in @selected_countries\")\n",
    "    rollup_filtered['Year'] = rollup_filtered['Year'].astype(str)\n",
    "\n",
    "    top5_df = rollup_filtered.groupby('Year', group_keys=False).apply(\n",
    "        lambda g: g.sort_values('TotalRevenueUZS', ascending=False).head(5)\n",
    "    )\n",
    "    top5_fig = px.bar(top5_df, x='Year', y='TotalRevenueUZS', color='Country', barmode='stack')\n",
    "    top5_fig.update_layout(xaxis_type='category')\n",
    "\n",
    "    line_fig = px.line(\n",
    "        rollup_filtered.groupby(['Year', 'Country'])['TotalRevenueUZS'].sum().reset_index(),\n",
    "        x='Year', y='TotalRevenueUZS', color='Country', markers=True\n",
    "    )\n",
    "    line_fig.update_layout(xaxis_type='category')\n",
    "\n",
    "    sliced = slice_dice_df.query(\"@y1 <= Year <= @y2\")\n",
    "    sliced['Year'] = sliced['Year'].astype(str)\n",
    "    geo = map_df.query(\"Country in @selected_countries\")\n",
    "\n",
    "    fig1 = px.bar(monthly, x=monthly['Year'].astype(str) + '-' + monthly['Month'].astype(str), y='MonthlyRevenue')\n",
    "    fig2 = px.bar(top, x='CategoryName', y='TotalRevenue')\n",
    "    fig3 = px.density_heatmap(pivot, x='CategoryName', y='Country', z='Revenue')\n",
    "    fig4 = px.histogram(seg, x='SpendTier', color='SpendTier', category_orders={\"SpendTier\": [\"Low\", \"Medium\", \"High\"]})\n",
    "    fig6 = px.bar(sliced, x='Year', y='Revenue')\n",
    "    fig7 = px.scatter_geo(geo, lat='Latitude', lon='Longitude', size='TotalRevenue', color='Country', hover_name='City', projection=\"natural earth\", size_max=20)\n",
    "\n",
    "    return fig1, fig2, fig3, fig4, top5_fig, line_fig, fig6, fig7\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, jupyter_mode='tab', port=8051)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
